import json
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from app.config import GOOGLE_API_KEY, CLUB_NAME, CLUB_INTRO, CLUB_POSITIONS, CLUB_DATA
from .state import ApplicationFormState, UserInfo, PositionInfo, QASessionIntent
from langgraph.graph import END

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-lite", temperature=0, api_key=GOOGLE_API_KEY)

intro_extractor = llm.with_structured_output(UserInfo)
position_extractor = llm.with_structured_output(PositionInfo)
intent_classifier_llm = llm.with_structured_output(QASessionIntent)


def start_node(state: ApplicationFormState):
    first_question = """ì¢‹ì•˜ì–´! ì´ì œ ë„¤ ì–˜ê¸°ë„ ì¢€ ë“¤ë ¤ì£¼ë¼. ê°„ë‹¨í•˜ê²Œ ìê¸°ì†Œê°œ í•œë²ˆ í•´ì¤„ ìˆ˜ ìˆì–´?"""
    return {
        "messages": [AIMessage(content=f"{first_question}")],
        "next_question": "intro"
    }


def process_introduction(state: ApplicationFormState):
    prompt = SystemMessage(content="ì‚¬ìš©ìì˜ ìµœì‹  ì‘ë‹µì—ì„œ ì´ë¦„, í•™ê³¼, ë‚˜ì´, ì „í™”ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•´. ë§Œì•½ íŠ¹ì • ì •ë³´ê°€ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ê·¸ ê°’ì€ ë°˜ë“œì‹œ Noneìœ¼ë¡œ ë‚¨ê²¨ë‘¬.")
    extracted_data: UserInfo = intro_extractor.invoke([prompt] + state["messages"])
    user_name = extracted_data.name if extracted_data.name else "ì§€ì›ì"
    next_question = f"ì†Œê°œ ê°ì‚¬í•©ë‹ˆë‹¤, {user_name}ë‹˜! {CLUB_POSITIONS} ì–´ë–¤ í¬ì§€ì…˜ì— ê´€ì‹¬ ìˆìœ¼ì‹ ê°€ìš”? (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥í•´ìš”)"
    return {
        "messages": [AIMessage(content=next_question)],
        "name": extracted_data.name,
        "department": extracted_data.department,
        "age": extracted_data.age,
        "phone_number": extracted_data.phone_number,
        "next_question": "position"
    }


def process_position(state: ApplicationFormState):
    prompt = SystemMessage(content=f"ì‚¬ìš©ìì˜ ìµœì‹  ì‘ë‹µì—ì„œ ê´€ì‹¬ìˆëŠ” í¬ì§€ì…˜ ëª©ë¡ì„ ì¶”ì¶œí•´. ì„ íƒì§€ëŠ” {CLUB_POSITIONS}ì´ì•¼.")
    try:
        extracted_data: PositionInfo = position_extractor.invoke([prompt] + state["messages"])
        if not extracted_data.positions: raise ValueError("í¬ì§€ì…˜ì´ ì„ íƒë˜ì§€ ì•ŠìŒ")
        next_question_text = "ì¢‹ìŠµë‹ˆë‹¤! ì´ì œ ì €í¬ ë™ì•„ë¦¬ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ë¥¼ í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
        return {
            "messages": [AIMessage(content=next_question_text)],
            "positions": extracted_data.positions,
            "next_question": "process_initial_motivation"
        }
    except Exception as e:
        retry_message = f"í¬ì§€ì…˜ì„ ì œëŒ€ë¡œ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš” ğŸ˜¥. {CLUB_POSITIONS} ì¤‘ì—ì„œ ê´€ì‹¬ìˆëŠ” í¬ì§€ì…˜ì„ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”."
        return {"messages": [AIMessage(content=retry_message)], "next_question": "position"}


def process_initial_motivation_node(state: ApplicationFormState):
    ack_message = """ì´ì•¼ê¸°í•´ì¤˜ì„œ ì •ë§ ê³ ë§ˆì›Œ! ë•ë¶„ì— ë„¤ê°€ ì–´ë–¤ ë©‹ì§„ ìƒê°ì„ í•˜ê³  ìˆëŠ”ì§€ ì˜ ì•Œ ìˆ˜ ìˆì—ˆì–´. ì ì´ì œë¶€í„°ëŠ” ë‚´ê°€ ë„ˆì˜ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ ì¤„ ì°¨ë¡€ì•¼ ìš°ë¦¬ ë™ì•„ë¦¬ì— ëŒ€í•´ ê¶ê¸ˆí–ˆë˜ê±°, í™œë™ì€ ì–´ë–»ê²Œ í•˜ëŠ”ì§€ ë“± ëª¨ë“ ì§€ í¸í•˜ê²Œ ë¬¼ì–´ë´!"""
    initial_motivation_text = state["messages"][-1].content
    return {
        "messages": [AIMessage(content=ack_message)],
        "initial_motivation": initial_motivation_text,
        "next_question": "qa_session"
    }


def qa_session_node(state: ApplicationFormState):
    user_message = state["messages"][-1].content
    classification: QASessionIntent = intent_classifier_llm.invoke(
        f"ì‚¬ìš©ì ë©”ì‹œì§€: '{user_message}'\n\nì´ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”. ('ì¢…ë£Œ', 'ê·¸ë§Œ', 'ëì–´', 'ì§€ì›ì„œ ìƒì„±')ëŠ” 'end_chat', ê·¸ ì™¸ëŠ” 'continue_chat'ì…ë‹ˆë‹¤."
    )

    if classification.intent == "end_chat":
        print("ëŒ€í™” ì¢…ë£Œ ê°ì§€ë¨ (qa_session_node)")
        return {"next_question": "generate_resume"}

    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", f"""
            ë‹¹ì‹ ì€ [{CLUB_NAME}]ì˜ í™ë³´ ë‹´ë‹¹ ì±—ë´‡ì…ë‹ˆë‹¤.
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œê·¼í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
            ì•„ë˜ [ë™ì•„ë¦¬ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
            [ë™ì•„ë¦¬ ì •ë³´]
            {CLUB_DATA}
            {CLUB_INTRO}
            {CLUB_POSITIONS}
            ---
            ì‚¬ìš©ìê°€ "ì¢…ë£Œ" ì‹ í˜¸ë¥¼ ë³´ë‚´ê¸° ì „ê¹Œì§€ ëŒ€í™”ë¥¼ ê³„ì† ì´ì–´ê°€ì„¸ìš”.
            """),
        MessagesPlaceholder(variable_name="history")
    ])
    qa_chain = qa_prompt | llm | StrOutputParser()
    response = qa_chain.invoke({"history": state["messages"][-10:]})
    return {
        "messages": [AIMessage(content=response)],
        "next_question": "qa_session"
    }


def generate_resume_node(state: ApplicationFormState):
    print("ğŸ¤– ì±—ë´‡: í”„ë¡œí•„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

    info = {
        "name": state.get("name") or "ì •ë³´ ì—†ìŒ",
        "department": state.get("department") or "ì •ë³´ ì—†ìŒ",
        "age": state.get("age") or "ì •ë³´ ì—†ìŒ",
        "phone_number": state.get("phone_number") or "ì •ë³´ ì—†ìŒ",
        "positions": ", ".join(state.get("positions") or ["ë¯¸ì§€ì •"]),
    }
    initial_motivation = state.get("initial_motivation")

    messages = state["messages"]
    qa_conversation = ""
    start_index = -1
    for i, msg in enumerate(messages):
        if "ì˜ ë“¤ì—ˆìŠµë‹ˆë‹¤!" in msg.content and isinstance(msg, AIMessage):
            start_index = i + 1
            break
    if start_index != -1:
        qa_texts = [f"- {msg.content}" for msg in messages[start_index:] if isinstance(msg, HumanMessage)]
        if qa_texts:
            last_message = qa_texts[-1].replace("- ", "")
            check_intent: QASessionIntent = intent_classifier_llm.invoke(f"'{last_message}'ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•´ì¤˜.")
            if check_intent.intent == "end_chat":
                qa_texts.pop()
        qa_conversation = "\n".join(qa_texts)
    if not qa_conversation:
        qa_conversation = "ì¶”ê°€ ì§ˆë¬¸ ì—†ìŒ"

    resume_prompt = f"""
                            # ì§€ì‹œì‚¬í•­
                            ë‹¹ì‹ ì€ ì „ë¬¸ ì±„ìš© ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ [ì§€ì›ì ì •ë³´]ì™€ [ì§€ì› ë™ê¸° ë° Q&A ë‚´ì—­]ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì˜ ê°•ì ê³¼ ì—´ì •ì´ ì˜ ë“œëŸ¬ë‚˜ëŠ” ë§¤ë ¥ì ì¸ ì´ë ¥ì„œ ìŠ¤íƒ€ì¼ì˜ í”„ë¡œí•„ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. 
                            [ì§€ì› ë™ê¸° ë° Q&A ë‚´ì—­]ì— í©ì–´ì ¸ ìˆëŠ” ì§€ì›ìì˜ ìƒê°ê³¼ ì§ˆë¬¸ë“¤ì„ í•˜ë‚˜ì˜ í†µì¼ëœ 'ì§€ì› ë™ê¸°' ìŠ¤í† ë¦¬ë¡œ ì—®ì–´ë‚´ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.

                            # [ì§€ì›ì ì •ë³´]
                            ì´ë¦„: {info['name']}
                            ì†Œì†: {info['department']} ({info['age']})
                            ì—°ë½ì²˜: {info['phone_number']}
                            í¬ë§ í¬ì§€ì…˜: {info['positions']}

                            # [ì´ˆê¸° ì§€ì› ë™ê¸°] (ì‚¬ìš©ìê°€ ì²˜ìŒì— ë°íŒ í•µì‹¬ ë™ê¸°)
                            {initial_motivation}

                            # [ì¶”ê°€ Q&A ë‚´ì—­] (ì´í›„ ëŒ€í™”ì—ì„œ ë“œëŸ¬ë‚œ ê´€ì‹¬ì‚¬)
                            {qa_conversation}

                            # ì¶œë ¥ í˜•ì‹ (ì˜ˆì‹œ)
                            ì´ë¦„: {info['name']}
                            ë‚˜ì´: {info['age']}
                            í•™ê³¼: {info['department']}
                            ì—°ë½ì²˜: {info['phone_number']}
                            í¬ë§ í¬ì§€ì…˜:{info['positions']}
                            ì§€ì› ë™ê¸°: (ì—¬ê¸°ì— [ì§€ì› ë™ê¸° ë° Q&A ë‚´ì—­]ì„ ë°”íƒ•ìœ¼ë¡œ LLMì´ ë©‹ì§€ê²Œ ìŠ¤í† ë¦¬ë¥¼ ì¬êµ¬ì„±í•œ ë‚´ìš©)
                            """

    generated_resume = llm.invoke(resume_prompt).content

    resume_summary = generated_resume

    profile_data = {
        "name": state.get("name"),
        "department": state.get("department"),
        "age": state.get("age"),
        "phone_number": state.get("phone_number"),
        "positions": state.get("positions"),
        "resume_summary": resume_summary
    }

    print("\n" + "=" * 30)
    print("ì§€ì›ì„œ")
    print("Data:")
    print(json.dumps(profile_data, indent=2, ensure_ascii=False))
    print("=" * 30 + "\n")

    final_message = f"ì§€ì›ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤."

    return {
        "messages": [AIMessage(content=final_message)],
        "resume_summary": resume_summary,
        "next_question": "done"
    }


def router(state: ApplicationFormState):
    if not state.get("messages", []):
        return "start"

    next_step = state.get("next_question", "intro")

    if next_step == "intro": return "process_introduction"
    if next_step == "position": return "process_position"
    if next_step == "process_initial_motivation": return "process_initial_motivation_node"
    if next_step == "qa_session": return "qa_session_node"
    if next_step == "generate_resume": return "generate_resume_node"
    if next_step == "done": return END