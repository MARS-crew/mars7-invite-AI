import json
import httpx
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from app.config import GOOGLE_API_KEY, CLUB_NAME, CLUB_INTRO, CLUB_POSITIONS, CLUB_DATA
from .state import ApplicationFormState, UserInfo, PositionInfo, QASessionIntent
from langgraph.graph import END

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-lite", temperature=0, api_key=GOOGLE_API_KEY)

intro_extractor = llm.with_structured_output(UserInfo)
position_extractor = llm.with_structured_output(PositionInfo)
intent_classifier_llm = llm.with_structured_output(QASessionIntent)


def start_node(state: ApplicationFormState):
    first_question = """ì¢‹ì•˜ì–´! ì´ì œ ë„¤ ì–˜ê¸°ë„ ì¢€ ë“¤ë ¤ì£¼ë¼. ê°„ë‹¨í•˜ê²Œ ìê¸°ì†Œê°œ í•œë²ˆ í•´ì¤„ ìˆ˜ ìˆì–´?"""
    return {
        "messages": [AIMessage(content=f"{first_question}")],
        "next_question": "intro"
    }


def process_introduction(state: ApplicationFormState):
    prompt = SystemMessage(content="ì‚¬ìš©ìì˜ ìµœì‹  ì‘ë‹µì—ì„œ ì´ë¦„, í•™ê³¼, ë‚˜ì´, ì „í™”ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•´. ë§Œì•½ íŠ¹ì • ì •ë³´ê°€ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ê·¸ ê°’ì€ ë°˜ë“œì‹œ Noneìœ¼ë¡œ ë‚¨ê²¨ë‘¬.")
    extracted_data: UserInfo = intro_extractor.invoke([prompt] + state["messages"])
    user_name = extracted_data.name if extracted_data.name else "ì§€ì›ì"
    next_question = f"{user_name[-2:]}!, ê·¸ë ‡êµ¬ë‚˜ ë„ˆëŠ” ì–´ë–¤ í¬ì§€ì…˜ì— ê´€ì‹¬ ìˆë‹ˆ?"
    return {
        "messages": [AIMessage(content=next_question)],
        "name": extracted_data.name,
        "department": extracted_data.department,
        "age": extracted_data.age,
        "phone_number": extracted_data.phone_number,
        "next_question": "position"
    }


def process_position(state: ApplicationFormState):
    prompt = SystemMessage(content=f"ì‚¬ìš©ìì˜ ìµœì‹  ì‘ë‹µì—ì„œ ê´€ì‹¬ìˆëŠ” í¬ì§€ì…˜ ëª©ë¡ì„ ì¶”ì¶œí•´. ì„ íƒì§€ëŠ” {CLUB_POSITIONS}ì´ì•¼.")
    try:
        extracted_data: PositionInfo = position_extractor.invoke([prompt] + state["messages"])
        if not extracted_data.positions: raise ValueError("í¬ì§€ì…˜ì´ ì„ íƒë˜ì§€ ì•ŠìŒ")
        next_question_text = "ì¢‹ì•„! ì´ì œ ë™ì•„ë¦¬ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ë¥¼ í¸í•˜ê²Œ ë§í•´ì¤„ë˜?"
        return {
            "messages": [AIMessage(content=next_question_text)],
            "positions": extracted_data.positions,
            "next_question": "process_initial_motivation"
        }
    except Exception as e:
        retry_message = f"í¬ì§€ì…˜ì„ ì œëŒ€ë¡œ ì´í•´í•˜ì§€ ëª»ì–´, {CLUB_POSITIONS} ì¤‘ì—ì„œ ê´€ì‹¬ìˆëŠ” í¬ì§€ì…˜ì„ ë‹¤ì‹œ ë§í•´ì¤˜!"
        return {"messages": [AIMessage(content=retry_message)], "next_question": "position"}


def process_initial_motivation_node(state: ApplicationFormState):
    ack_message = """ì´ì•¼ê¸°í•´ì¤˜ì„œ ì •ë§ ê³ ë§ˆì›Œ! ë•ë¶„ì— ë„¤ê°€ ì–´ë–¤ ë©‹ì§„ ìƒê°ì„ í•˜ê³  ìˆëŠ”ì§€ ì˜ ì•Œ ìˆ˜ ìˆì—ˆì–´. ì ì´ì œë¶€í„°ëŠ” ë‚´ê°€ ë„ˆì˜ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ ì¤„ ì°¨ë¡€ì•¼ ìš°ë¦¬ ë™ì•„ë¦¬ì— ëŒ€í•´ ê¶ê¸ˆí–ˆë˜ê±°, í™œë™ì€ ì–´ë–»ê²Œ í•˜ëŠ”ì§€ ë“± ëª¨ë“ ì§€ í¸í•˜ê²Œ ë¬¼ì–´ë´!"""
    initial_motivation_text = state["messages"][-1].content
    return {
        "messages": [AIMessage(content=ack_message)],
        "initial_motivation": initial_motivation_text,
        "next_question": "qa_session"
    }


def qa_session_node(state: ApplicationFormState):
    user_message = state["messages"][-1].content
    classification: QASessionIntent = intent_classifier_llm.invoke(f"ì‚¬ìš©ì ë©”ì‹œì§€: '{user_message}'\n\nì´ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”. ('ì¢…ë£Œ', 'ê·¸ë§Œ', 'ëì–´', 'ì§€ì›ì„œ ìƒì„±')ëŠ” 'end_chat', ê·¸ ì™¸ëŠ” 'continue_chat'ì…ë‹ˆë‹¤.")

    if classification.intent == "end_chat":
        print("ëŒ€í™” ì¢…ë£Œ ê°ì§€ë¨ (qa_session_node)")
        return {"next_question": "generate_resume"}

    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", f"""
            ë‹¹ì‹ ì€ [{CLUB_NAME}]ì˜ í™ë³´ ë‹´ë‹¹ ì±—ë´‡ì…ë‹ˆë‹¤.
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œê·¼í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
            ì•„ë˜ [ë™ì•„ë¦¬ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
            [ë™ì•„ë¦¬ ì •ë³´]
            {CLUB_DATA}
            {CLUB_INTRO}
            {CLUB_POSITIONS}
            ---
            ì‚¬ìš©ìê°€ "ì¢…ë£Œ" ì‹ í˜¸ë¥¼ ë³´ë‚´ê¸° ì „ê¹Œì§€ ëŒ€í™”ë¥¼ ê³„ì† ì´ì–´ê°€ì„¸ìš”.
            Markdown í—¤ë”(##), ì œëª©, ì´ëª¨í‹°ì½˜, ë˜ëŠ” ê¸°íƒ€ ì„œì‹ì„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            """),
        MessagesPlaceholder(variable_name="history")
    ])
    qa_chain = qa_prompt | llm | StrOutputParser()
    response = qa_chain.invoke({"history": state["messages"][-10:]})
    return {
        "messages": [AIMessage(content=response)],
        "next_question": "qa_session"
    }


def generate_resume_node(state: ApplicationFormState):
    print("ğŸ¤– ì±—ë´‡: í”„ë¡œí•„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

    info = {
        "name": state.get("name") or "ì •ë³´ ì—†ìŒ",
        "department": state.get("department") or "ì •ë³´ ì—†ìŒ",
        "age": state.get("age") or "ì •ë³´ ì—†ìŒ",
        "phone_number": state.get("phone_number") or "ì •ë³´ ì—†ìŒ",
        "positions": ", ".join(state.get("positions") or ["ë¯¸ì§€ì •"]),
    }
    initial_motivation = state.get("initial_motivation")

    messages = state["messages"]
    qa_conversation = ""
    start_index = -1
    for i, msg in enumerate(messages):
        if "ì˜ ë“¤ì—ˆìŠµë‹ˆë‹¤!" in msg.content and isinstance(msg, AIMessage):
            start_index = i + 1
            break
    if start_index != -1:
        qa_texts = [f"- {msg.content}" for msg in messages[start_index:] if isinstance(msg, HumanMessage)]
        if qa_texts:
            last_message = qa_texts[-1].replace("- ", "")
            check_intent: QASessionIntent = intent_classifier_llm.invoke(f"'{last_message}'ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•´ì¤˜.")
            if check_intent.intent == "end_chat":
                qa_texts.pop()
        qa_conversation = "\n".join(qa_texts)
    if not qa_conversation:
        qa_conversation = "ì¶”ê°€ ì§ˆë¬¸ ì—†ìŒ"

    resume_prompt = f"""
                            # ì§€ì‹œì‚¬í•­
                            ë‹¹ì‹ ì€ ì§€ì›ì ë³¸ì¸ ì…ë‹ˆë‹¤. ì•„ë˜ [ì§€ì›ì ì •ë³´]ì™€ [ëŒ€í™” ë‚´ì—­]ì„ ë°”íƒ•ìœ¼ë¡œ, ì˜¤ì§ 'ì§€ì› ë™ê¸° ë° í¬ë¶€'ì— ëŒ€í•œ ë¬¸ë‹¨(paragraph)ë§Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
                            [ëŒ€í™” ë‚´ì—­]ì— í©ì–´ì ¸ ìˆëŠ” ì§€ì›ìì˜ ìƒê°ê³¼ ì§ˆë¬¸ë“¤ì„ í•˜ë‚˜ì˜ í†µì¼ëœ 'ì§€ì› ë™ê¸°' ìŠ¤í† ë¦¬ë¡œ ì—®ì–´ë‚´ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.

                            # [ì§€ì›ì ì •ë³´]
                            ì´ë¦„: {info['name']}
                            ì†Œì†: {info['department']} ({info['age']})
                            ì—°ë½ì²˜: {info['phone_number']}
                            í¬ë§ í¬ì§€ì…˜: {info['positions']}

                            # [ì´ˆê¸° ì§€ì› ë™ê¸°] (ì‚¬ìš©ìê°€ ì²˜ìŒì— ë°íŒ í•µì‹¬ ë™ê¸°)
                            {initial_motivation}

                            # [ì¶”ê°€ Q&A ë‚´ì—­] (ì´í›„ ëŒ€í™”ì—ì„œ ë“œëŸ¬ë‚œ ê´€ì‹¬ì‚¬)
                            {qa_conversation}

                            # ì¶œë ¥ ê·œì¹™
                            - 300ì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.
                            - ì´ë¦„, í•™ê³¼ ë“± ê°œì¸ì •ë³´ë¥¼ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.
                            - Markdown í—¤ë”(##), ì œëª©, ë˜ëŠ” ê¸°íƒ€ ì„œì‹ì„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
                            - ì˜¤ì§ 'ì§€ì› ë™ê¸° ë° í¬ë¶€' ë¬¸ë‹¨ ìì²´ë§Œ ì‘ë‹µí•˜ì„¸ìš”.
                            """

    generated_resume = llm.invoke(resume_prompt).content
    motivation = generated_resume

    profile_data = {
        "name": state.get("name"),
        "department": state.get("department"),
        "age": state.get("age"),
        "phone_number": state.get("phone_number"),
        "positions": state.get("positions"),
        "motivation": motivation
    }

    final_message = ""
    try:
        submit_url = "https://d1ixjsazi0u8mj.cloudfront.net/submit"

        print(f"ğŸš€ [ì „ì†¡ ì‹œë„] Endpoint: {submit_url}\n{profile_data}")
        response = httpx.post(submit_url, json=profile_data)

        response.raise_for_status()

    except httpx.HTTPStatusError as e:
        print(f"[ì „ì†¡ ì‹¤íŒ¨] ì„œë²„ê°€ ì˜¤ë¥˜ë¥¼ ë°˜í™˜: {e}")
        final_message = "í”„ë¡œí•„ ìƒì„±ì— ì„±ê³µí–ˆìœ¼ë‚˜, ìµœì¢… ì œì¶œ ì„œë²„ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    except httpx.RequestError as e:
        print(f"[ì „ì†¡ ì‹¤íŒ¨] ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŒ: {e}")
        final_message = "í”„ë¡œí•„ ìƒì„±ì— ì„±ê³µí–ˆìœ¼ë‚˜, ì œì¶œ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"[ì „ì†¡ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜]: {e}")
        final_message = "í”„ë¡œí•„ ìƒì„± ë˜ëŠ” ì œì¶œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    return {
        "messages": [AIMessage(content=final_message)],
        "motivation": motivation,
        "next_question": "done"
    }


def router(state: ApplicationFormState):
    if not state.get("messages", []):
        return "start"

    next_step = state.get("next_question", "intro")

    if next_step == "intro": return "process_introduction"
    if next_step == "position": return "process_position"
    if next_step == "process_initial_motivation": return "process_initial_motivation_node"
    if next_step == "qa_session": return "qa_session_node"
    if next_step == "generate_resume": return "generate_resume_node"
    if next_step == "done": return END